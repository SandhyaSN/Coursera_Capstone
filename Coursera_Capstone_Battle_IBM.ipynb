{
    "nbformat": 4, 
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Coursera Capstone Project"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Loading the essential libraries, or install if not already available"
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n# !conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n!conda install -c conda-forge geopy --yes\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20181108054459-0000\nSolving environment: \\ "
                }
            ], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## 1. Introduction to the Objective of this Capstone Project"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "This Notebook will be used to analyze the areas around a central, focal point, as they would appear in a rectangular grid of roughly 5 X 5 points with almost 1 km distances between them. In longitude and latitude terms, 1 km is roughly 1 minute of a degree both to the North - South and to the East - West direction.\n\nThe center can be determined by the user, by setting the \"Central_Address\" variable to an address which should be initially recognized by the Google geocode API. The API call should return the original coordinates. Following this, a dataframe with the 25 neighborhoods, all around this central point are fetched.\n\nThe **objective** of this exercise is to cluster these 25 neighborhoods and provide suggestions about how much the patterns and the profile of the city changes when someone moves away from their original point of interest. This POI might be the hotel they are going to stay in, a new home, their business address or anything else that they need to analyze from a \"what is near\" viewpoint."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "As a first step, we determine the address and retrieve its coordinates with an API call to Google maps."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "API_key = 'AIzaSyA57R4UMqyiVNiVnEOTF9rjYDcHgzLaSto'\n\nCentral_Address = 'Diovounioti 1, Chalandri 15231, Greece'\n# construct URL to make API call\nurl = 'https://maps.googleapis.com/maps/api/geocode/json?key={}&address={}'.format(API_key, Central_Address)\n    \nresponse = requests.get(url).json() # get response\n# print(response)\ntry:\n    geographical_data = response['results'][0]['geometry']['location'] # get geographical coordinates\n    central_latitude = geographical_data['lat']\n    central_longitude = geographical_data['lng']\n    print('The central point has latitude {} and longitude {}.'.format(central_latitude, central_longitude))\nexcept:\n    print('Oops for {}!'.format(Central_Address))\n    print(response)\n", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Following a successful completion of the first call, we setup the virtual grid of 5X5 points around this conceptual pin on the map, moving each time roughly 1km from the central point."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "# Create the grid around the central point\nlist_of_points = []\nfm_deg_to_km = 0.01\nfor north_south in range(2,-3,-1):\n    for east_west in range(2,-3,-1):\n        list_of_points.append((central_latitude+north_south*fm_deg_to_km, central_longitude+east_west*fm_deg_to_km, north_south, east_west))\nlen(list_of_points)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Convert the list into a Python dataframe, which is easier to handle and enrich."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "df = pd.DataFrame(list_of_points)\ndf.columns = ['Latitude', 'Longitude', 'North_South', 'East_West']", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "For each point of the 5x5 grid, we get the actual address (e.g. street, neighborhood, country etc.)."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "from geopy.geocoders import GoogleV3\ngeolocator = GoogleV3(API_key)\nfor latitude, longitude in zip(df['Latitude'], df['Longitude']):\n    location = geolocator.reverse('{}, {}'.format(latitude, longitude))\n    address_fm_GPS = location[0][0].split(',')\n    Street = address_fm_GPS[0]\n    Neighborhood = address_fm_GPS[1]\n    Country = address_fm_GPS[2]\n    cond = ((df['Latitude'] == latitude) & (df['Longitude'] == longitude))\n    col01 = 'Street'\n    col02 = 'Neighborhood'\n    col03 = 'Country'\n    df.loc[cond, col01] = Street\n    df.loc[cond, col02] = Neighborhood\n    df.loc[cond, col03] = Country\ndf.head()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Explore the Dataframe"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "We can run a few basic statistics on the derived dataset."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "df.groupby('Neighborhood')['Neighborhood'].count()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "df[df['Neighborhood'].str.contains('152 31')]", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# 2. Explore and cluster the neighborhoods around the central point."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Methodology: At this point, we have the grid of the 25 points around the central address we had selected in the very beginning. For each one of them, we will make a call to Foursquare and retrieve the 100 top venues and associate them with their category. We will then generate summary statistics for the categories mostly located in each neighborhood and finally, cluster the neighborhoods based on their similarity of the type of venues included. "
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Before we start, we can have a quick look of how our grid looks like on the map."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "# create map of Canada using latitude and longitude values\nmap_of_POI = folium.Map(location=[central_latitude, central_longitude], zoom_start=12)\n\n# add markers to map\nfor lat, lng, neighborhood, street in zip(df['Latitude'], df['Longitude'], df['Neighborhood'], df['Street']):\n    label = '{}, {}'.format(neighborhood, street)\n    label = folium.Popup(label, parse_html=True)\n    if lat == central_latitude and lng == central_longitude:\n        color = 'red'\n    else:\n        color = 'blue'\n    folium.CircleMarker(\n        [lat, lng],\n        radius=3,\n        popup=label,\n        color=color,\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_of_POI)  \n    \nmap_of_POI", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Define Foursquare credentials and Version"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "The following paragraphs fetch all the venues information from Foursquare."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "# The code was removed by Watson Studio for sharing.\nCLIENT_ID = 'YILUDYB0P1W1X4HNOK5C3AVVWFY3LK1NZAX4AJGVUESNOFPG'\nCLIENT_SECRET = 'I2LT5WEAFU5PGXYCYALNWAWAXGGFSC5L2C1AZGWWW1YQDUSM'\nLIMIT = 100\nVERSION = 20180901", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        # results = requests.get(url).json()\n        # print(results)\n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_venues = getNearbyVenues(df['Neighborhood'], df['Latitude'], df['Longitude'], radius=500)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "print(All_around_venues.shape)\nAll_around_venues.head()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_venues.loc[All_around_venues['Venue Category'] == 'ATM']", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_venues.groupby('Neighborhood')['Neighborhood'].count()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "print('There are {} unique categories.'.format(All_around_venues['Venue Category'].nunique()))", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "print('There are {} unique neighborhoods.'.format(All_around_venues['Neighborhood'].nunique()))", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### 2a. Analyze each neighborhood"
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "# one hot encoding\nAll_around_onehot = pd.get_dummies(All_around_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add grid coordination columns back to dataframe\nAll_around_onehot['Neighborhood'] = All_around_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [All_around_onehot.columns[-1]] + list(All_around_onehot.columns[:-1])\nAll_around_onehot = All_around_onehot[fixed_columns]\n\nAll_around_onehot.head()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_onehot.shape", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Given that some points of the grid fall into the same neighborhood, we recalculate the grid by averaging the coordinates of all the points within the same neighborhood."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_by_Neighborhood = df[['Neighborhood','Latitude','Longitude']].groupby('Neighborhood').mean().reset_index()\nAll_around_by_Neighborhood", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_grouped = All_around_onehot.groupby('Neighborhood').mean().reset_index()\nAll_around_grouped", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_grouped.shape", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "We take a quick look at the most common venues for each neighborhood."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "num_top_venues = 5\n\nfor hood in All_around_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = All_around_grouped[All_around_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    '''    \n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n    '''\n    if ind <= 2:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    else:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n    \n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = All_around_grouped['Neighborhood']\n\nfor ind in np.arange(All_around_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(All_around_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### 2b. Clustering Step"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Given the number of distinct neighborhoods cannot exceed 25, we believe a total number of 5 clusters is both sufficient and simple enough."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "# set number of clusters\nkclusters = 5\n\nAll_around_grouped_clustering = All_around_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(All_around_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_grouped.shape", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_merged = All_around_by_Neighborhood\n\n# add clustering labels\nAll_around_merged['Cluster Labels'] = kmeans.labels_\n\n# merge back to original dataframe to add latitude/longitude for each neighborhood\nAll_around_merged = All_around_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\n\n\nAll_around_merged.head() # check the last columns!", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "# create map\nmap_clusters = folium.Map(location=[central_latitude, central_longitude], zoom_start=12)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(All_around_merged['Latitude'], All_around_merged['Longitude'], All_around_merged['Neighborhood'], All_around_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters\n", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### 2c. Examine the generated Clusters"
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "print(All_around_merged.groupby('Cluster Labels')['Cluster Labels'].count())", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nID_columns = ['Neighborhood', 'Cluster Labels']\nshow_columns = [x for x in All_around_merged.columns if x.find('Venue') > 0]\nAll_around_merged.loc[All_around_merged['Cluster Labels'] == 0, ID_columns + show_columns]\n", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Understand each one of the clusters in more detail."
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_merged.loc[All_around_merged['Cluster Labels'] == 0, ID_columns + show_columns]", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_merged.loc[All_around_merged['Cluster Labels'] == 1, ID_columns + show_columns]", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_merged.loc[All_around_merged['Cluster Labels'] == 2, ID_columns + show_columns]", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_merged.loc[All_around_merged['Cluster Labels'] == 3, ID_columns + show_columns]", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "source": "All_around_merged.loc[All_around_merged['Cluster Labels'] == 4, ID_columns + show_columns]", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Conclusion"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "The clustering exercise managed to identify 4 unique areas (differentiated mostly by their Souvlaki Shops, Scenic Lookout, Bus Stop and Movie Theater respectively), where the type of venues is clearly disimilar to that of the remaining neighborhoods. Cluster 0 includes mostly mixed neighborhoods, but conherently with loads of coffee shops and restaurants."
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "language": "python3", 
            "name": "python3"
        }, 
        "language_info": {
            "version": "3.5.4", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "pygments_lexer": "ipython3", 
            "name": "python", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat_minor": 2
}